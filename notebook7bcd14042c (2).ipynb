{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13119958,"sourceType":"datasetVersion","datasetId":8311195}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-21T05:27:17.971346Z","iopub.execute_input":"2025-09-21T05:27:17.971668Z","iopub.status.idle":"2025-09-21T05:27:18.800886Z","shell.execute_reply.started":"2025-09-21T05:27:17.971641Z","shell.execute_reply":"2025-09-21T05:27:18.800032Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/urdu-roman-dataset/parallel_clean.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\ndata_path = '/kaggle/input/urdu-roman-dataset'  # replace with your folder name\nprint(os.listdir(data_path))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:26:57.929388Z","iopub.execute_input":"2025-09-21T14:26:57.929705Z","iopub.status.idle":"2025-09-21T14:26:57.937411Z","shell.execute_reply.started":"2025-09-21T14:26:57.929680Z","shell.execute_reply":"2025-09-21T14:26:57.936318Z"}},"outputs":[{"name":"stdout","text":"['parallel_clean.csv']\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\n# List all datasets in /kaggle/input\nprint(os.listdir('/kaggle/input'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:27:07.933470Z","iopub.execute_input":"2025-09-21T14:27:07.933837Z","iopub.status.idle":"2025-09-21T14:27:07.939312Z","shell.execute_reply.started":"2025-09-21T14:27:07.933812Z","shell.execute_reply":"2025-09-21T14:27:07.938299Z"}},"outputs":[{"name":"stdout","text":"['urdu-roman-dataset']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Step 1: List all top-level dataset folders in /kaggle/input\ndatasets = os.listdir('/kaggle/input')\nprint(\"Available datasets:\", datasets)\n\n# Step 2: If you know part of your dataset name, find it automatically\ndataset_name = None\nfor d in datasets:\n    if 'urdu' in d.lower():  # change 'urdu' to a unique keyword in your dataset name\n        dataset_name = d\n        break\n\nif dataset_name is None:\n    print(\"Dataset not found. Please check that it is added via 'Add data'.\")\nelse:\n    data_path = f'/kaggle/input/{dataset_name}'\n    print(\"Dataset folder found:\", data_path)\n    \n    # Step 3: List all files in the dataset folder\n    files = os.listdir(data_path)\n    print(\"Files in dataset:\", files)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:27:21.007389Z","iopub.execute_input":"2025-09-21T14:27:21.007728Z","iopub.status.idle":"2025-09-21T14:27:21.015689Z","shell.execute_reply.started":"2025-09-21T14:27:21.007703Z","shell.execute_reply":"2025-09-21T14:27:21.014640Z"}},"outputs":[{"name":"stdout","text":"Available datasets: ['urdu-roman-dataset']\nDataset folder found: /kaggle/input/urdu-roman-dataset\nFiles in dataset: ['parallel_clean.csv']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\n\n# Get all CSV files in the folder\ncsv_files = [f for f in os.listdir(data_path) if f.endswith('.csv')]\n\n# Load each CSV into a dictionary\ndataframes = {}\nfor f in csv_files:\n    df_name = f.replace('.csv', '')  # key = file name without .csv\n    dataframes[df_name] = pd.read_csv(f'{data_path}/{f}')\n\n# Check what keys are in dataframes\nprint(\"Loaded CSVs:\", list(dataframes.keys()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:27:29.059996Z","iopub.execute_input":"2025-09-21T14:27:29.060323Z","iopub.status.idle":"2025-09-21T14:27:29.505991Z","shell.execute_reply.started":"2025-09-21T14:27:29.060298Z","shell.execute_reply":"2025-09-21T14:27:29.504472Z"}},"outputs":[{"name":"stdout","text":"Loaded CSVs: ['parallel_clean']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# -------------------------------\n# Step 1: List all datasets in Kaggle input\n# -------------------------------\ndatasets = os.listdir('/kaggle/input')\nprint(\"Available datasets:\", datasets)\n\n# -------------------------------\n# Step 2: Automatically find your dataset folder\n# -------------------------------\ndataset_name = None\nfor d in datasets:\n    if 'urdu' in d.lower():  # change 'urdu' to a keyword unique to your dataset\n        dataset_name = d\n        break\n\nif dataset_name is None:\n    print(\"Dataset not found. Please add it via 'Add data'.\")\nelse:\n    data_path = f'/kaggle/input/{dataset_name}'\n    print(\"Dataset folder found:\", data_path)\n\n    # -------------------------------\n    # Step 3: List all files in the dataset folder\n    # -------------------------------\n    files = os.listdir(data_path)\n    print(\"Files in dataset:\", files)\n\n    # -------------------------------\n    # Step 4: Load all CSV files into a dictionary\n    # -------------------------------\n    csv_files = [f for f in files if f.endswith('.csv')]\n    dataframes = {}\n    for f in csv_files:\n        df_name = f.replace('.csv', '')\n        dataframes[df_name] = pd.read_csv(f'{data_path}/{f}')\n        print(f\"Loaded {f} with shape {dataframes[df_name].shape}\")\n\n    # -------------------------------\n    # Step 5: Preview the first CSV\n    # -------------------------------\n    df = dataframes[list(dataframes.keys())[0]]\n    print(\"\\nPreview of first CSV:\")\n    print(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:27:36.844349Z","iopub.execute_input":"2025-09-21T14:27:36.844670Z","iopub.status.idle":"2025-09-21T14:27:36.913980Z","shell.execute_reply.started":"2025-09-21T14:27:36.844648Z","shell.execute_reply":"2025-09-21T14:27:36.912997Z"}},"outputs":[{"name":"stdout","text":"Available datasets: ['urdu-roman-dataset']\nDataset folder found: /kaggle/input/urdu-roman-dataset\nFiles in dataset: ['parallel_clean.csv']\nLoaded parallel_clean.csv with shape (1314, 2)\n\nPreview of first CSV:\n                                                urdu  \\\n0  اہٹ سی کوئی ائے تو لگتا ہے کہ تم ہو سایہ کوئی ...   \n1  موج گل موج صبا موج سحر لگتی ہے سر سے پا تک وہ ...   \n2  طلوع صبح ہے نظریں اٹھا کے دیکھ ذرا شکست ظلمت ش...   \n3  ہم سے بھاگا نہ کرو دور غزالوں کی طرح ہم نے چاہ...   \n4  ہر ایک روح میں اک غم چھپا لگے ہے مجھے یہ زندگی...   \n\n                                               roman  \n0  aahat s ko aa.e to lagt hai ki tum ho saaya ko...  \n1  mauj e gul mauj e sab mauj e sahar lagt hai sa...  \n2  tul e sub.h hai nazre uth ke dekh zar shikast ...  \n3  ham se bh g na karo duur haz lo k tarah ham ne...  \n4  har ek ruuh me ik ham chhup lage hai mujhe ye ...  \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import re\nfrom sklearn.model_selection import train_test_split\n\n# -------------------------------\n# Step 1: Use the loaded DataFrame\n# -------------------------------\n# 'df' is already your first CSV loaded\ndf = df.dropna().drop_duplicates().reset_index(drop=True)\n\n# -------------------------------\n# Step 2: Rename columns for clarity\n# -------------------------------\n# Replace these with the actual column names from your dataset\ndf = df.rename(columns={'urdu_column_name': 'urdu', 'roman_column_name': 'roman'})\n\n# -------------------------------\n# Step 3: Text cleaning function\n# -------------------------------\ndef clean_text(text):\n    \"\"\"\n    Remove unwanted characters, punctuation, and extra spaces\n    \"\"\"\n    text = str(text)\n    text = text.strip()                  # Remove leading/trailing spaces\n    text = re.sub(r'\\s+', ' ', text)     # Replace multiple spaces with one\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    return text\n\n# Apply cleaning to both columns\ndf['urdu'] = df['urdu'].apply(clean_text)\ndf['roman'] = df['roman'].apply(clean_text)\n\n# -------------------------------\n# Step 4: Inspect cleaned data\n# -------------------------------\nprint(\"Sample data after cleaning:\")\nprint(df.head())\n\n# -------------------------------\n# Step 5: Split into train and validation sets\n# -------------------------------\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\nprint(\"Training set shape:\", train_df.shape)\nprint(\"Validation set shape:\", val_df.shape)\n\n# -------------------------------\n# Step 6: Save preprocessed data (optional)\n# -------------------------------\ntrain_df.to_csv('/kaggle/working/train_data.csv', index=False)\nval_df.to_csv('/kaggle/working/val_data.csv', index=False)\n\nprint(\"Preprocessed data saved to /kaggle/working/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:27:52.932565Z","iopub.execute_input":"2025-09-21T14:27:52.932894Z","iopub.status.idle":"2025-09-21T14:27:54.021022Z","shell.execute_reply.started":"2025-09-21T14:27:52.932870Z","shell.execute_reply":"2025-09-21T14:27:54.019742Z"}},"outputs":[{"name":"stdout","text":"Sample data after cleaning:\n                                                urdu  \\\n0  اہٹ سی کوئی ائے تو لگتا ہے کہ تم ہو سایہ کوئی ...   \n1  موج گل موج صبا موج سحر لگتی ہے سر سے پا تک وہ ...   \n2  طلوع صبح ہے نظریں اٹھا کے دیکھ ذرا شکست ظلمت ش...   \n3  ہم سے بھاگا نہ کرو دور غزالوں کی طرح ہم نے چاہ...   \n4  ہر ایک روح میں اک غم چھپا لگے ہے مجھے یہ زندگی...   \n\n                                               roman  \n0  aahat s ko aae to lagt hai ki tum ho saaya ko ...  \n1  mauj e gul mauj e sab mauj e sahar lagt hai sa...  \n2  tul e subh hai nazre uth ke dekh zar shikast e...  \n3  ham se bh g na karo duur haz lo k tarah ham ne...  \n4  har ek ruuh me ik ham chhup lage hai mujhe ye ...  \nTraining set shape: (1182, 2)\nValidation set shape: (132, 2)\nPreprocessed data saved to /kaggle/working/\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from tokenizers import ByteLevelBPETokenizer\nfrom tokenizers.processors import BertProcessing\nfrom tokenizers import Tokenizer, trainers, pre_tokenizers\nimport os\n\n# -------------------------------\n# Step 1: Save text files for tokenizer training\n# -------------------------------\ntrain_urdu_path = '/kaggle/working/train_urdu.txt'\ntrain_roman_path = '/kaggle/working/train_roman.txt'\n\n# Save training sentences to text files\nwith open(train_urdu_path, 'w', encoding='utf-8') as f:\n    for sent in train_df['urdu']:\n        f.write(sent + '\\n')\n\nwith open(train_roman_path, 'w', encoding='utf-8') as f:\n    for sent in train_df['roman']:\n        f.write(sent + '\\n')\n\n# -------------------------------\n# Step 2: Initialize Byte-Pair Encoding (BPE) tokenizers\n# -------------------------------\n# Source tokenizer (Urdu)\ntokenizer_urdu = ByteLevelBPETokenizer()\ntokenizer_urdu.train(files=[train_urdu_path], vocab_size=30000, min_frequency=2, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n\n# Target tokenizer (Roman Urdu)\ntokenizer_roman = ByteLevelBPETokenizer()\ntokenizer_roman.train(files=[train_roman_path], vocab_size=30000, min_frequency=2, special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"])\n\n# -------------------------------\n# Step 3: Encode sentences into token IDs\n# -------------------------------\n# Example: Encode first 5 sentences\nencoded_urdu = [tokenizer_urdu.encode(s).ids for s in train_df['urdu'][:5]]\nencoded_roman = [tokenizer_roman.encode(s).ids for s in train_df['roman'][:5]]\n\nprint(\"Example Urdu token IDs:\", encoded_urdu)\nprint(\"Example Roman Urdu token IDs:\", encoded_roman)\n\n# -------------------------------\n# Step 4: Prepare sequences for model training\n# -------------------------------\n# You can pad/truncate sequences for batch training\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nmax_len_src = 50  # max sequence length for Urdu\nmax_len_tgt = 50  # max sequence length for Roman Urdu\n\nX_train = pad_sequences([tokenizer_urdu.encode(s).ids for s in train_df['urdu']], maxlen=max_len_src, padding='post', truncating='post')\ny_train = pad_sequences([tokenizer_roman.encode(s).ids for s in train_df['roman']], maxlen=max_len_tgt, padding='post', truncating='post')\n\nX_val = pad_sequences([tokenizer_urdu.encode(s).ids for s in val_df['urdu']], maxlen=max_len_src, padding='post', truncating='post')\ny_val = pad_sequences([tokenizer_roman.encode(s).ids for s in val_df['roman']], maxlen=max_len_tgt, padding='post', truncating='post')\n\nprint(\"Training shapes:\", X_train.shape, y_train.shape)\nprint(\"Validation shapes:\", X_val.shape, y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:28:07.592874Z","iopub.execute_input":"2025-09-21T14:28:07.593198Z","iopub.status.idle":"2025-09-21T14:28:28.191006Z","shell.execute_reply.started":"2025-09-21T14:28:07.593176Z","shell.execute_reply":"2025-09-21T14:28:28.189709Z"}},"outputs":[{"name":"stdout","text":"\n\n\n\n\n\nExample Urdu token IDs: [[986, 1471, 945, 313, 384, 304, 2443, 423, 291, 958, 565, 438, 1200, 7787, 524, 318, 936, 2758, 335, 538, 2246, 308, 723, 524, 469, 341, 526, 663, 2730, 3237, 300, 291, 1917, 297, 4773, 1110, 335, 291, 768, 297, 497, 308, 7156, 4195, 1214, 308, 1157, 291, 3261, 719, 592, 273, 317, 2698, 1072, 2570, 291, 438, 1435, 1214, 524, 336, 341, 2885, 327, 313, 300, 514, 372, 300, 302, 3013, 3068, 2011, 297, 610, 2390, 297, 1042, 293, 683, 302, 1841, 297, 2010, 6639, 302, 1268, 7001, 393, 310, 4339, 812, 291, 346, 6920, 7251, 1052, 307, 438, 313, 715, 6364, 6624, 308, 2267, 300, 291, 2639, 346, 2679, 630, 4626, 291, 873, 313, 274, 706, 291, 599, 416, 279, 2544, 1006, 363, 348, 310, 2095, 937, 4321, 316, 976, 300, 291, 659, 525, 2590, 383, 291, 758, 4890, 310, 323, 3488, 693, 316, 1390, 307, 574, 610, 291, 1407, 693, 316, 1390, 307, 568, 4338, 300, 291, 573, 334, 310], [263, 375, 4003, 300, 326, 1707, 1872, 2069, 291, 1938, 340, 291, 4326, 318, 2033, 2069, 291, 346, 1506, 1133, 291, 1600, 386, 1480, 467, 1059, 388, 3739, 323, 1728, 1872, 2069, 291, 4587, 318, 821, 291, 406, 399, 2797, 308, 762, 313, 3383, 3383, 346, 864, 5029, 2069, 291, 2221, 5741, 308, 558, 7249, 339, 720, 1373, 4426, 622, 723, 454, 3364, 2069, 291, 454, 328, 316, 927, 300, 407, 3429, 471, 339, 821, 341, 574, 2453, 304, 420, 326, 2033, 2069, 291], [1462, 386, 318, 291, 302, 1092, 297, 3891, 585, 307, 594, 302, 577, 476, 3954, 491, 332, 1147, 637, 388, 635, 5207, 476, 1124, 339, 1650, 339, 411, 339, 3274, 339, 954, 327, 356, 707, 383, 332, 744, 635, 1929, 476, 454, 341, 1580, 340, 542, 1557, 814, 889, 878, 672, 1557, 372, 386, 296, 1870, 976, 1810, 300, 926, 3483, 476, 7997, 3638, 718, 4383, 3422, 588, 409, 3872, 701, 386, 1999, 869, 825, 1368, 682, 577, 476, 1960, 1110, 297, 754, 446, 3131, 300, 1320, 462, 327, 1157, 307, 805, 971, 446, 307, 3559, 1472, 476, 608, 399, 328, 383, 608, 6977, 356, 504, 4928, 308, 1082, 514, 383, 3474, 291, 744, 304, 7371, 476, 1421, 341, 2146, 1222, 297, 588, 792, 346, 1328, 934, 3116, 606, 300, 332, 2129, 499, 773, 300, 341, 3711, 476, 1206, 341, 339, 565, 1964, 2196, 341, 409, 604, 825, 439, 304, 296, 2357, 297, 340, 1413, 328, 308, 1062, 300, 468, 476, 758, 3337, 316, 1371, 647, 307, 656, 754, 327, 6721, 1593, 1593, 335, 2145, 719, 719, 476], [3503, 5617, 525, 2132, 308, 760, 420, 423, 2970, 514, 556, 308, 760, 673, 366, 1408, 529, 666, 1830, 497, 328, 308, 339, 1818, 308, 760, 291, 3393, 352, 323, 781, 300, 1348, 340, 291, 2684, 2223, 323, 1958, 308, 760, 682, 2540, 308, 3792, 424, 634, 2984, 308, 3147, 1803, 308, 760, 327, 5680, 1194, 456, 793, 6744, 3615, 669, 3147, 1479, 308, 760, 1459, 415, 366, 836, 335, 291, 2500, 340, 620, 291, 693, 2045, 308, 760, 1621, 300, 7543, 291, 3218, 519, 343, 1183, 739, 491, 6382, 308, 760], [279, 2818, 692, 316, 1051, 300, 291, 3790, 340, 4959, 323, 2745, 608, 715, 2582, 291, 6032, 367, 2278, 323, 1499, 291, 438, 387, 998, 4374, 306, 4632, 307, 4339, 5075, 3250, 304, 524, 505, 327, 674, 2028, 323, 487, 1204, 316, 4595, 1908, 323, 987, 1014, 1738, 313, 300, 366, 4790, 336, 3766, 2865, 1995, 7334, 323, 4169, 1588, 428, 1471, 697, 4888, 406, 326, 339, 1739, 363, 522, 264, 616, 6639, 291, 7842, 719, 1224, 2278, 323, 3122, 1517, 297, 2234, 297, 927, 925, 339, 384, 304, 302, 336, 4260, 6460, 310, 307, 2318, 1807, 4466, 323, 499, 307, 318, 366, 437, 2393, 2252, 305, 291, 346, 4570, 262, 313, 4131, 7892, 310, 300, 291, 622, 409, 2932, 323]]\nExample Roman Urdu token IDs: [[1359, 1221, 270, 274, 291, 312, 350, 288, 1738, 387, 272, 737, 391, 402, 1052, 270, 427, 641, 282, 327, 308, 329, 592, 326, 311, 367, 1685, 274, 262, 639, 1241, 328, 391, 457, 1622, 270, 2162, 262, 283, 272, 492, 274, 335, 4230, 531, 268, 311, 272, 531, 282, 335, 469, 262, 4555, 269, 391, 262, 981, 272, 2158, 261, 270, 279, 267, 279, 928, 2004, 272, 402, 1160, 270, 391, 327, 314, 328, 295, 1391, 272, 312, 344, 467, 534, 283, 284, 332, 461, 274, 270, 278, 262, 335, 470, 261, 270, 1568, 335, 3410, 270, 627, 284, 265, 282, 335, 1557, 270, 325, 274, 284, 1071, 270, 2162, 268, 2997, 412, 272, 330, 378, 276, 270, 3644, 380, 287, 402, 312, 694, 270, 1906, 873, 262, 1366, 283, 272, 663, 330, 262, 1784, 268, 566, 267, 489, 265, 272, 296, 755, 312, 310, 332, 272, 572, 572, 558, 270, 1885, 625, 4126, 1923, 672, 270, 274, 265, 225, 300, 835, 283, 272, 366, 366, 1992, 371, 272, 261, 553, 3032, 279, 619, 262, 1972, 339, 300, 1146, 287, 378, 470, 261, 272, 1162, 339, 300, 1146, 287, 526, 1403, 283, 272, 3215, 76], [587, 2926, 283, 301, 1384, 455, 282, 1420, 272, 1518, 319, 272, 574, 308, 1061, 282, 1420, 272, 330, 779, 436, 753, 272, 888, 261, 667, 481, 919, 288, 855, 225, 262, 1112, 455, 282, 1420, 272, 3105, 308, 439, 272, 372, 368, 1774, 268, 262, 680, 312, 2456, 2456, 330, 761, 1968, 282, 1420, 272, 316, 270, 316, 335, 262, 512, 271, 1892, 317, 1599, 4664, 397, 639, 427, 2475, 282, 1420, 272, 427, 339, 300, 1445, 283, 388, 1585, 271, 432, 317, 439, 328, 378, 1921, 288, 383, 301, 1061, 282, 1420, 272], [1283, 261, 308, 272, 284, 336, 279, 335, 2862, 543, 287, 538, 284, 503, 448, 1983, 440, 306, 548, 274, 654, 288, 594, 1104, 270, 448, 1800, 317, 1375, 317, 364, 317, 759, 317, 803, 272, 1938, 371, 306, 486, 594, 497, 270, 448, 427, 328, 771, 282, 270, 319, 2883, 264, 589, 270, 792, 270, 267, 265, 727, 534, 261, 304, 1788, 326, 835, 1399, 283, 313, 261, 822, 270, 448, 3139, 270, 2128, 276, 592, 267, 2312, 270, 267, 291, 354, 2040, 261, 397, 261, 1607, 270, 740, 261, 504, 264, 1119, 617, 503, 448, 1564, 270, 531, 268, 335, 724, 270, 306, 2151, 283, 1099, 428, 272, 981, 287, 708, 841, 306, 287, 2432, 268, 1451, 448, 559, 368, 339, 371, 559, 270, 1748, 332, 331, 760, 1113, 262, 934, 467, 371, 2513, 271, 272, 486, 288, 1178, 270, 448, 581, 328, 793, 274, 270, 2386, 335, 267, 291, 676, 330, 630, 269, 270, 278, 264, 270, 2082, 277, 767, 283, 306, 717, 329, 690, 283, 328, 760, 270, 448, 683, 328, 317, 391, 1273, 1479, 328, 1257, 504, 404, 288, 304, 2510, 335, 319, 1519, 339, 262, 689, 283, 442, 448, 225, 261, 553, 270, 2376, 300, 316, 486, 578, 287, 659, 724, 272, 4353, 3343, 3343, 311, 262, 817, 930, 930, 448], [1930, 3737, 366, 1670, 262, 705, 383, 387, 801, 467, 510, 262, 705, 665, 322, 989, 482, 624, 270, 296, 274, 469, 339, 262, 317, 3098, 262, 705, 272, 1476, 282, 434, 262, 1740, 283, 698, 319, 272, 3089, 764, 262, 511, 262, 705, 617, 740, 753, 274, 262, 614, 225, 355, 575, 1890, 262, 2310, 1555, 262, 705, 272, 516, 1084, 984, 398, 703, 270, 4369, 2558, 605, 2310, 1198, 262, 705, 265, 261, 274, 322, 743, 462, 272, 1895, 319, 367, 272, 339, 2044, 262, 705, 1323, 283, 278, 262, 269, 291, 272, 267, 276, 225, 485, 1871, 276, 270, 440, 4294, 262, 705], [81, 518, 303, 81, 300, 750, 283, 272, 844, 562, 319, 872, 291, 262, 2097, 559, 270, 694, 279, 274, 272, 1317, 267, 270, 261, 291, 262, 601, 873, 272, 402, 289, 870, 391, 687, 271, 267, 270, 3145, 287, 2997, 296, 261, 2375, 288, 327, 447, 272, 261, 262, 269, 291, 262, 460, 1025, 300, 284, 2918, 411, 262, 656, 291, 270, 830, 1209, 312, 344, 322, 4034, 314, 1287, 384, 562, 296, 261, 269, 291, 262, 2885, 1116, 414, 1221, 270, 282, 693, 261, 372, 301, 317, 1211, 946, 261, 270, 582, 325, 274, 272, 1288, 523, 261, 270, 630, 291, 262, 1093, 264, 270, 269, 406, 335, 265, 267, 335, 276, 265, 471, 317, 350, 288, 284, 314, 261, 274, 3623, 3269, 287, 876, 291, 296, 436, 264, 291, 262, 329, 287, 268, 322, 394, 1827, 282, 264, 349, 272, 330, 3291, 312, 2822, 278, 2209, 304, 283, 272, 397, 354, 845, 291, 262]]\n","output_type":"stream"},{"name":"stderr","text":"2025-09-21 14:28:10.438864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758464890.697460      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758464890.777336      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Training shapes: (1182, 50) (1182, 50)\nValidation shapes: (132, 50) (132, 50)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, LSTM, Bidirectional, Embedding, Dense\nimport numpy as np\n\n# -------------------------------\n# Parameters (based on your preprocessing)\n# -------------------------------\nsrc_vocab_size = tokenizer_urdu.get_vocab_size()\ntgt_vocab_size = tokenizer_roman.get_vocab_size()\nembedding_dim = 256\nencoder_units = 256\ndecoder_units = 256\nmax_len_src = X_train.shape[1]\nmax_len_tgt = X_train.shape[1]\n\n# -------------------------------\n# Encoder: 2-layer BiLSTM\n# -------------------------------\nencoder_inputs = Input(shape=(max_len_src,), name='encoder_input')\nencoder_embedding = Embedding(input_dim=src_vocab_size, output_dim=embedding_dim, mask_zero=True)(encoder_inputs)\n\n# First BiLSTM layer\nencoder_bi1 = Bidirectional(LSTM(encoder_units, return_sequences=True, return_state=True))\nencoder_out1, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_bi1(encoder_embedding)\nstate_h1 = tf.keras.layers.Concatenate()([forward_h1, backward_h1])\nstate_c1 = tf.keras.layers.Concatenate()([forward_c1, backward_c1])\n\n# Second BiLSTM layer\nencoder_bi2 = Bidirectional(LSTM(encoder_units, return_sequences=True, return_state=True))\nencoder_out2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_bi2(encoder_out1)\nstate_h2 = tf.keras.layers.Concatenate()([forward_h2, backward_h2])\nstate_c2 = tf.keras.layers.Concatenate()([forward_c2, backward_c2])\n\nencoder_states = [state_h2, state_c2]\n\n# -------------------------------\n# Decoder: 4-layer LSTM\n# -------------------------------\ndecoder_inputs = Input(shape=(max_len_tgt,), name='decoder_input')\ndecoder_embedding = Embedding(input_dim=tgt_vocab_size, output_dim=embedding_dim, mask_zero=True)(decoder_inputs)\n\ndecoder_lstm1 = LSTM(decoder_units*2, return_sequences=True, return_state=True)\ndecoder_out1, _, _ = decoder_lstm1(decoder_embedding, initial_state=encoder_states)\n\ndecoder_lstm2 = LSTM(decoder_units*2, return_sequences=True, return_state=True)\ndecoder_out2, _, _ = decoder_lstm2(decoder_out1)\n\ndecoder_lstm3 = LSTM(decoder_units*2, return_sequences=True, return_state=True)\ndecoder_out3, _, _ = decoder_lstm3(decoder_out2)\n\ndecoder_lstm4 = LSTM(decoder_units*2, return_sequences=True, return_state=True)\ndecoder_out4, _, _ = decoder_lstm4(decoder_out3)\n\ndecoder_dense = Dense(tgt_vocab_size, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_out4)\n\n# -------------------------------\n# Define the model\n# -------------------------------\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# -------------------------------\n# Prepare target data for teacher forcing\n# -------------------------------\ny_train_shifted = np.zeros_like(y_train)\ny_train_shifted[:, :-1] = y_train[:, 1:]\ny_val_shifted = np.zeros_like(y_val)\ny_val_shifted[:, :-1] = y_val[:, 1:]\n\n# -------------------------------\n# Train the model\n# -------------------------------\nhistory = model.fit(\n    [X_train, y_train],\n    np.expand_dims(y_train_shifted, -1),\n    validation_data=([X_val, y_val], np.expand_dims(y_val_shifted, -1)),\n    batch_size=32,  # reduce if memory issues\n    epochs=10\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:28:32.593876Z","iopub.execute_input":"2025-09-21T14:28:32.594446Z","iopub.status.idle":"2025-09-21T14:48:46.025341Z","shell.execute_reply.started":"2025-09-21T14:28:32.594420Z","shell.execute_reply":"2025-09-21T14:48:46.024288Z"}},"outputs":[{"name":"stderr","text":"2025-09-21 14:28:32.626339: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m2,059,520\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,050,624\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_1     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,574,912\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │  \u001b[38;5;34m1,253,120\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ bidirectional_1[\u001b[38;5;34m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m1,574,912\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │ concatenate_3[\u001b[38;5;34m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m512\u001b[0m), │  \u001b[38;5;34m2,099,200\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m),      │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m4895\u001b[0m)  │  \u001b[38;5;34m2,511,135\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,059,520</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ bidirectional_1     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,253,120</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ bidirectional_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>), │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,200</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>),      │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)]      │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4895</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,511,135</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,321,823\u001b[0m (62.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,321,823</span> (62.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,321,823\u001b[0m (62.26 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,321,823</span> (62.26 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 3s/step - accuracy: 0.0354 - loss: 7.2984 - val_accuracy: 0.0365 - val_loss: 6.2520\nEpoch 2/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 3s/step - accuracy: 0.0409 - loss: 6.2139 - val_accuracy: 0.0379 - val_loss: 6.2220\nEpoch 3/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 3s/step - accuracy: 0.0431 - loss: 6.1714 - val_accuracy: 0.0362 - val_loss: 6.1975\nEpoch 4/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step - accuracy: 0.0413 - loss: 6.1610 - val_accuracy: 0.0373 - val_loss: 6.1894\nEpoch 5/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 3s/step - accuracy: 0.0413 - loss: 6.1480 - val_accuracy: 0.0400 - val_loss: 6.1704\nEpoch 6/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 3s/step - accuracy: 0.0424 - loss: 6.1417 - val_accuracy: 0.0365 - val_loss: 6.1724\nEpoch 7/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 3s/step - accuracy: 0.0439 - loss: 6.1452 - val_accuracy: 0.0565 - val_loss: 6.1750\nEpoch 8/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step - accuracy: 0.0546 - loss: 6.1143 - val_accuracy: 0.0362 - val_loss: 6.1627\nEpoch 9/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 3s/step - accuracy: 0.0522 - loss: 6.1077 - val_accuracy: 0.0498 - val_loss: 6.1535\nEpoch 10/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 3s/step - accuracy: 0.0589 - loss: 6.0952 - val_accuracy: 0.0550 - val_loss: 6.1200\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# -------------------------------\n# STEP 0: Imports\n# -------------------------------\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# -------------------------------\n# STEP 1: Dataset Split 50/25/25\n# -------------------------------\nall_urdu = df['urdu'].values\nall_roman = df['roman'].values\n\n# First split: 50% train, 50% temp\nX_train_raw, X_temp_raw, y_train_raw, y_temp_raw = train_test_split(\n    all_urdu, all_roman, test_size=0.5, random_state=42)\n\n# Second split: 25% val, 25% test\nX_val_raw, X_test_raw, y_val_raw, y_test_raw = train_test_split(\n    X_temp_raw, y_temp_raw, test_size=0.5, random_state=42)\n\nprint(len(X_train_raw), len(X_val_raw), len(X_test_raw))\n\n# -------------------------------\n# STEP 2: Encode & Pad sequences using BPE tokenizers\n# -------------------------------\nmax_len_src = 50\nmax_len_tgt = 50\n\ndef encode_pad(tokenizer, sentences, max_len):\n    sequences = [tokenizer.encode(s).ids for s in sentences]\n    sequences = [seq + [0]*(max_len - len(seq)) if len(seq)<max_len else seq[:max_len] for seq in sequences]\n    return sequences\n\nX_train = encode_pad(tokenizer_urdu, X_train_raw, max_len_src)\ny_train = encode_pad(tokenizer_roman, y_train_raw, max_len_tgt)\nX_val = encode_pad(tokenizer_urdu, X_val_raw, max_len_src)\ny_val = encode_pad(tokenizer_roman, y_val_raw, max_len_tgt)\nX_test = encode_pad(tokenizer_urdu, X_test_raw, max_len_src)\ny_test = encode_pad(tokenizer_roman, y_test_raw, max_len_tgt)\n\n# Convert to tensors\nX_train = torch.tensor(X_train, dtype=torch.long)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_val = torch.tensor(X_val, dtype=torch.long)\ny_val = torch.tensor(y_val, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.long)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\n# -------------------------------\n# STEP 3: PyTorch Dataset & DataLoader\n# -------------------------------\nclass NMTDataset(Dataset):\n    def __init__(self, src, tgt):\n        self.src = src\n        self.tgt = tgt\n        \n    def __len__(self):\n        return len(self.src)\n    \n    def __getitem__(self, idx):\n        return self.src[idx], self.tgt[idx]\n\nbatch_size = 32\ntrain_dataset = NMTDataset(X_train, y_train)\nval_dataset = NMTDataset(X_val, y_val)\ntest_dataset = NMTDataset(X_test, y_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)\n\n# -------------------------------\n# STEP 4: Seq2Seq Model in PyTorch\n# -------------------------------\n\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, n_layers, dropout=0.1):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n        self.lstm_layers = nn.ModuleList()\n        for i in range(n_layers):\n            self.lstm_layers.append(nn.LSTM(emb_dim if i==0 else enc_hid_dim*2, enc_hid_dim, num_layers=1, bidirectional=True, batch_first=True))\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, src):\n        embedded = self.dropout(self.embedding(src))\n        outputs = embedded\n        for lstm in self.lstm_layers:\n            outputs, (hidden, cell) = lstm(outputs)\n        # concatenate final forward and backward hidden states\n        hidden = torch.cat([hidden[0], hidden[1]], dim=1).unsqueeze(0)\n        cell = torch.cat([cell[0], cell[1]], dim=1).unsqueeze(0)\n        return outputs, (hidden, cell)\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, dec_hid_dim, n_layers, dropout=0.1):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n        self.lstm_layers = nn.ModuleList()\n        for i in range(n_layers):\n            self.lstm_layers.append(nn.LSTM(emb_dim if i==0 else dec_hid_dim*2, dec_hid_dim*2, num_layers=1, batch_first=True))\n        self.fc_out = nn.Linear(dec_hid_dim*2, output_dim)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, tgt, hidden, cell):\n        embedded = self.dropout(self.embedding(tgt))\n        outputs = embedded\n        for lstm in self.lstm_layers:\n            outputs, (hidden, cell) = lstm(outputs, (hidden, cell))\n        predictions = self.fc_out(outputs)\n        return predictions, (hidden, cell)\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def forward(self, src, tgt):\n        encoder_outputs, (hidden, cell) = self.encoder(src)\n        outputs, _ = self.decoder(tgt, hidden, cell)\n        return outputs\n\n# Model instantiation\nenc = Encoder(input_dim=tokenizer_urdu.get_vocab_size(), emb_dim=256, enc_hid_dim=256, n_layers=2).to(device)\ndec = Decoder(output_dim=tokenizer_roman.get_vocab_size(), emb_dim=256, dec_hid_dim=256, n_layers=4).to(device)\nmodel = Seq2Seq(enc, dec).to(device)\n\n# -------------------------------\n# STEP 5: Loss & Optimizer\n# -------------------------------\ncriterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)\n\n# -------------------------------\n# STEP 6: Training Loop (simplified)\n# -------------------------------\nn_epochs = 10\nfor epoch in range(n_epochs):\n    model.train()\n    epoch_loss = 0\n    for src_batch, tgt_batch in train_loader:\n        src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n        optimizer.zero_grad()\n        # shift target for teacher forcing\n        tgt_input = tgt_batch[:, :-1]\n        tgt_output = tgt_batch[:, 1:]\n        output = model(src_batch, tgt_input)\n        output = output.view(-1, output.shape[-1])\n        tgt_output = tgt_output.contiguous().view(-1)\n        loss = criterion(output, tgt_output)\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(train_loader):.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T14:50:50.602855Z","iopub.execute_input":"2025-09-21T14:50:50.603237Z","iopub.status.idle":"2025-09-21T14:56:18.857705Z","shell.execute_reply.started":"2025-09-21T14:50:50.603214Z","shell.execute_reply":"2025-09-21T14:56:18.856795Z"}},"outputs":[{"name":"stdout","text":"657 328 329\nEpoch 1, Loss: 6.8554\nEpoch 2, Loss: 6.1871\nEpoch 3, Loss: 6.1443\nEpoch 4, Loss: 6.1270\nEpoch 5, Loss: 6.1134\nEpoch 6, Loss: 6.0970\nEpoch 7, Loss: 6.0891\nEpoch 8, Loss: 6.0760\nEpoch 9, Loss: 6.0639\nEpoch 10, Loss: 6.0493\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# -------------------------------\n# STEP 7: Training + Validation Loop\n# -------------------------------\nimport math\nimport nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n\nsmooth = SmoothingFunction().method1\n\ndef evaluate(model, loader, criterion):\n    model.eval()\n    epoch_loss = 0\n    all_preds, all_refs = [], []\n    \n    with torch.no_grad():\n        for src_batch, tgt_batch in loader:\n            src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n\n            tgt_input = tgt_batch[:, :-1]   # input to decoder\n            tgt_output = tgt_batch[:, 1:]   # expected output\n\n            output = model(src_batch, tgt_input)   # [batch, seq, vocab]\n            output_dim = output.shape[-1]\n\n            output_flat = output.view(-1, output_dim)\n            tgt_output_flat = tgt_output.contiguous().view(-1)\n\n            loss = criterion(output_flat, tgt_output_flat)\n            epoch_loss += loss.item()\n\n            # Predictions for BLEU\n            preds = output.argmax(-1).cpu().numpy()\n            refs = tgt_output.cpu().numpy()\n\n            for p, r in zip(preds, refs):\n                p = [idx for idx in p if idx != 0]\n                r = [idx for idx in r if idx != 0]\n                if len(p) > 0 and len(r) > 0:\n                    bleu = sentence_bleu([r], p, smoothing_function=smooth)\n                    all_preds.append(bleu)\n\n    avg_loss = epoch_loss / len(loader)\n    ppl = math.exp(avg_loss) if avg_loss < 20 else float(\"inf\")\n    avg_bleu = np.mean(all_preds) if len(all_preds) > 0 else 0.0\n\n    return avg_loss, ppl, avg_bleu\n\n\n# -------------------------------\n# STEP 8: Train with Validation\n# -------------------------------\nn_epochs = 10\nfor epoch in range(n_epochs):\n    model.train()\n    train_loss = 0\n\n    for src_batch, tgt_batch in train_loader:\n        src_batch, tgt_batch = src_batch.to(device), tgt_batch.to(device)\n        optimizer.zero_grad()\n\n        tgt_input = tgt_batch[:, :-1]\n        tgt_output = tgt_batch[:, 1:]\n\n        output = model(src_batch, tgt_input)\n        output_dim = output.shape[-1]\n\n        output_flat = output.view(-1, output_dim)\n        tgt_output_flat = tgt_output.contiguous().view(-1)\n\n        loss = criterion(output_flat, tgt_output_flat)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n\n    # Validation at end of epoch\n    val_loss, val_ppl, val_bleu = evaluate(model, val_loader, criterion)\n\n    print(f\"Epoch {epoch+1}: \"\n          f\"Train Loss={train_loss/len(train_loader):.4f} | \"\n          f\"Val Loss={val_loss:.4f}, Val PPL={val_ppl:.2f}, Val BLEU={val_bleu:.4f}\")\n\n\n# -------------------------------\n# STEP 9: Final Test Evaluation\n# -------------------------------\ntest_loss, test_ppl, test_bleu = evaluate(model, test_loader, criterion)\nprint(f\"\\nFinal Test Results -> Loss={test_loss:.4f}, PPL={test_ppl:.2f}, BLEU={test_bleu:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:10:35.774963Z","iopub.execute_input":"2025-09-21T15:10:35.775315Z","iopub.status.idle":"2025-09-21T15:16:58.854981Z","shell.execute_reply.started":"2025-09-21T15:10:35.775288Z","shell.execute_reply":"2025-09-21T15:16:58.853990Z"}},"outputs":[{"name":"stdout","text":"Epoch 1: Train Loss=5.8828 | Val Loss=6.3136, Val PPL=552.05, Val BLEU=0.0055\nEpoch 2: Train Loss=5.8528 | Val Loss=6.3091, Val PPL=549.55, Val BLEU=0.0056\nEpoch 3: Train Loss=5.8204 | Val Loss=6.2994, Val PPL=544.23, Val BLEU=0.0054\nEpoch 4: Train Loss=5.7764 | Val Loss=6.2673, Val PPL=527.03, Val BLEU=0.0058\nEpoch 5: Train Loss=5.7273 | Val Loss=6.2439, Val PPL=514.84, Val BLEU=0.0057\nEpoch 6: Train Loss=5.6691 | Val Loss=6.2372, Val PPL=511.44, Val BLEU=0.0072\nEpoch 7: Train Loss=5.6050 | Val Loss=6.2134, Val PPL=499.40, Val BLEU=0.0077\nEpoch 8: Train Loss=5.5228 | Val Loss=6.1922, Val PPL=488.91, Val BLEU=0.0081\nEpoch 9: Train Loss=5.4415 | Val Loss=6.1829, Val PPL=484.39, Val BLEU=0.0083\nEpoch 10: Train Loss=5.3664 | Val Loss=6.1830, Val PPL=484.46, Val BLEU=0.0085\n\nFinal Test Results -> Loss=6.1527, PPL=469.96, BLEU=0.0086\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# -------------------------------\n# STEP 10: Inference (Qualitative Examples)\n# -------------------------------\n\ndef translate_sentence(model, sentence, tokenizer_src, tokenizer_tgt, max_len=50):\n    model.eval()\n\n    # 1. Encode Urdu sentence\n    src_ids = tokenizer_src.encode(sentence).ids\n    src_ids = src_ids[:max_len] + [0]*(max_len - len(src_ids))  # pad\n    src_tensor = torch.tensor([src_ids], dtype=torch.long).to(device)\n\n    # 2. Start with <sos> token for decoder (use id=1 if tokenizer has special tokens)\n    tgt_ids = [1]  # assuming 1 = <sos>\n    for _ in range(max_len):\n        tgt_tensor = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n        with torch.no_grad():\n            output = model(src_tensor, tgt_tensor)  # [1, seq_len, vocab_size]\n        next_token = output[0, -1].argmax(-1).item()\n        tgt_ids.append(next_token)\n        if next_token == 2:  # assuming 2 = <eos>\n            break\n\n    # 3. Decode predicted Roman Urdu ids back to text\n    pred_sentence = tokenizer_tgt.decode(tgt_ids)\n    return pred_sentence\n\n\n# -------------------------------\n# Example Usage\n# -------------------------------\nsample_urdu = \"میں تجھ کو بھول جاؤں گا\"\npredicted_roman = translate_sentence(model, sample_urdu, tokenizer_urdu, tokenizer_roman)\nprint(\"Urdu Input:\", sample_urdu)\nprint(\"Predicted Roman Urdu:\", predicted_roman)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:17:10.340102Z","iopub.execute_input":"2025-09-21T15:17:10.340436Z","iopub.status.idle":"2025-09-21T15:17:12.093885Z","shell.execute_reply.started":"2025-09-21T15:17:10.340412Z","shell.execute_reply":"2025-09-21T15:17:12.092812Z"}},"outputs":[{"name":"stdout","text":"Urdu Input: میں تجھ کو بھول جاؤں گا\nPredicted Roman Urdu:  to to bh bh mai mai bh bh bh bh bh to to th to th th th th th th th th th th th th th bh k mai k mai k mai k mai k mai k mai k mai k mai k mai k mai k\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def translate_sentence(model, sentence, tokenizer_src, tokenizer_tgt, max_len=50):\n    model.eval()\n\n    src_ids = tokenizer_src.encode(sentence).ids\n    src_ids = src_ids[:max_len] + [0]*(max_len - len(src_ids))\n    src_tensor = torch.tensor([src_ids], dtype=torch.long).to(device)\n\n    tgt_ids = [1]  # <sos>\n    for _ in range(max_len):\n        tgt_tensor = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n        with torch.no_grad():\n            output = model(src_tensor, tgt_tensor)\n        next_token = output[0, -1].argmax(-1).item()\n\n        if next_token == 2:  # <eos>\n            break\n        if len(tgt_ids) > 2 and next_token == tgt_ids[-1]:  # avoid loops\n            break\n\n        tgt_ids.append(next_token)\n\n    pred_sentence = tokenizer_tgt.decode(tgt_ids)\n    return pred_sentence\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:19:43.703577Z","iopub.execute_input":"2025-09-21T15:19:43.705019Z","iopub.status.idle":"2025-09-21T15:19:43.712663Z","shell.execute_reply.started":"2025-09-21T15:19:43.704975Z","shell.execute_reply":"2025-09-21T15:19:43.711536Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"print(\"Urdu tokenizer vocab size:\", tokenizer_urdu.get_vocab_size())\nprint(\"Roman tokenizer vocab size:\", tokenizer_roman.get_vocab_size())\n\n# Print first few tokens\nprint(\"Roman vocab sample:\", list(tokenizer_roman.get_vocab().items())[:20])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:20:42.283586Z","iopub.execute_input":"2025-09-21T15:20:42.284032Z","iopub.status.idle":"2025-09-21T15:20:42.299505Z","shell.execute_reply.started":"2025-09-21T15:20:42.284004Z","shell.execute_reply":"2025-09-21T15:20:42.298427Z"}},"outputs":[{"name":"stdout","text":"Urdu tokenizer vocab size: 8045\nRoman tokenizer vocab size: 4895\nRoman vocab sample: [('Ġaiso', 3783), ('Ġbha', 1791), ('Ġizzat', 2544), ('Ġafsh', 1762), ('Ĩ', 233), ('ç', 168), ('Ġgust', 2065), ('ı', 242), ('Ġnikhat', 2184), ('Ġhikmat', 3125), ('Ġguhar', 1555), ('Ġbuute', 4695), ('Ġsamt', 1558), ('Ġanv', 4428), ('Ġlekin', 608), ('Ġhum', 1218), ('ist', 892), ('Ġpyaar', 853), ('Ġaf', 674), ('Ġleh', 4333)]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"def translate_sentence(model, sentence, tokenizer_src, tokenizer_tgt, max_len=50):\n    model.eval()\n\n    # Encode Urdu input\n    src_ids = tokenizer_src.encode(sentence).ids\n    src_ids = src_ids[:max_len] + [0]*(max_len - len(src_ids))   # padding\n    src_tensor = torch.tensor([src_ids], dtype=torch.long).to(device)\n\n    # Start with an empty target sequence (or PAD=0)\n    tgt_ids = [0]\n\n    for _ in range(max_len):\n        tgt_tensor = torch.tensor([tgt_ids], dtype=torch.long).to(device)\n        with torch.no_grad():\n            output = model(src_tensor, tgt_tensor)\n        next_token = output[0, -1].argmax(-1).item()\n\n        # Stop if next token is PAD (0)\n        if next_token == 0:\n            break\n\n        tgt_ids.append(next_token)\n\n    # Decode predicted tokens into Roman Urdu string\n    pred_sentence = tokenizer_tgt.decode(tgt_ids)\n    return pred_sentence\n\n\n# 🔥 Example test\nsample_urdu = \"میں تجھ کو بھول جاؤں گا\"\npredicted_roman = translate_sentence(model, sample_urdu, tokenizer_urdu, tokenizer_roman)\nprint(\"Urdu Input:\", sample_urdu)\nprint(\"Predicted Roman Urdu:\", predicted_roman)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:21:33.902890Z","iopub.execute_input":"2025-09-21T15:21:33.904080Z","iopub.status.idle":"2025-09-21T15:21:35.550402Z","shell.execute_reply.started":"2025-09-21T15:21:33.904035Z","shell.execute_reply":"2025-09-21T15:21:35.549421Z"}},"outputs":[{"name":"stdout","text":"Urdu Input: میں تجھ کو بھول جاؤں گا\nPredicted Roman Urdu:  to to bh bh mai mai bh bh bh bh bh to to bh th to th th th th th th th th th th th th bh k mai k mai k mai k mai k mai k mai k mai k mai k mai k mai k\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# =======================================================\n# COMBINED PIPELINE (Steps 1 → 6)\n# =======================================================\n\n# -------------------------------\n# STEP 0: Imports & Device\n# -------------------------------\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom tokenizers import ByteLevelBPETokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# -------------------------------\n# STEP 1: Add <sos>/<eos> tokens + Split 50/25/25\n# -------------------------------\ndf['roman_sos_eos'] = \"<sos> \" + df['roman'].astype(str) + \" <eos>\"\n\nall_src = df['urdu'].astype(str).tolist()\nall_tgt = df['roman_sos_eos'].astype(str).tolist()\n\nX_train_raw, X_temp_raw, y_train_raw, y_temp_raw = train_test_split(all_src, all_tgt, test_size=0.5, random_state=42)\nX_val_raw, X_test_raw, y_val_raw, y_test_raw = train_test_split(X_temp_raw, y_temp_raw, test_size=0.5, random_state=42)\n\nprint(\"Splits:\", len(X_train_raw), len(X_val_raw), len(X_test_raw))\n\n# -------------------------------\n# STEP 2: Train Roman tokenizer (with special tokens)\n# -------------------------------\ntrain_roman_path = '/kaggle/working/train_roman_with_tokens.txt'\nwith open(train_roman_path, 'w', encoding='utf-8') as f:\n    for s in y_train_raw:\n        f.write(s + '\\n')\n\ntokenizer_roman = ByteLevelBPETokenizer()\ntokenizer_roman.train(\n    files=[train_roman_path],\n    vocab_size=8000,\n    min_frequency=2,\n    special_tokens=[\"<sos>\", \"<pad>\", \"<eos>\", \"<unk>\", \"<mask>\"]\n)\n\n# Urdu tokenizer assumed already trained earlier\n# If not, you can retrain like this:\n# tokenizer_urdu = ByteLevelBPETokenizer()\n# tokenizer_urdu.train(files=['/kaggle/working/train_urdu.txt'],\n#                      vocab_size=8000, min_frequency=2,\n#                      special_tokens=[\"<pad>\", \"<unk>\"])\n\n# -------------------------------\n# STEP 3: Get special token IDs\n# -------------------------------\npad_id = tokenizer_roman.token_to_id(\"<pad>\")\nsos_id = tokenizer_roman.token_to_id(\"<sos>\")\neos_id = tokenizer_roman.token_to_id(\"<eos>\")\nsrc_pad_id = tokenizer_urdu.token_to_id(\"<pad>\") or 0\n\nprint(\"Roman pad:\", pad_id, \"sos:\", sos_id, \"eos:\", eos_id)\nprint(\"Urdu pad:\", src_pad_id)\n\n# -------------------------------\n# STEP 4: Encode & Pad\n# -------------------------------\nMAX_LEN_SRC = 50\nMAX_LEN_TGT = 50\n\ndef encode_pad(tokenizer, sentences, max_len, pad_id):\n    ids_list = []\n    for s in sentences:\n        enc = tokenizer.encode(s).ids\n        if len(enc) >= max_len:\n            ids_list.append(enc[:max_len])\n        else:\n            ids_list.append(enc + [pad_id] * (max_len - len(enc)))\n    return ids_list\n\nX_train_ids = encode_pad(tokenizer_urdu, X_train_raw, MAX_LEN_SRC, src_pad_id)\nX_val_ids   = encode_pad(tokenizer_urdu, X_val_raw, MAX_LEN_SRC, src_pad_id)\nX_test_ids  = encode_pad(tokenizer_urdu, X_test_raw, MAX_LEN_SRC, src_pad_id)\n\ny_train_ids = encode_pad(tokenizer_roman, y_train_raw, MAX_LEN_TGT, pad_id)\ny_val_ids   = encode_pad(tokenizer_roman, y_val_raw, MAX_LEN_TGT, pad_id)\ny_test_ids  = encode_pad(tokenizer_roman, y_test_raw, MAX_LEN_TGT, pad_id)\n\nX_train = torch.tensor(X_train_ids, dtype=torch.long)\ny_train = torch.tensor(y_train_ids, dtype=torch.long)\nX_val   = torch.tensor(X_val_ids, dtype=torch.long)\ny_val   = torch.tensor(y_val_ids, dtype=torch.long)\nX_test  = torch.tensor(X_test_ids, dtype=torch.long)\ny_test  = torch.tensor(y_test_ids, dtype=torch.long)\n\n# -------------------------------\n# STEP 5: Dataset & DataLoader\n# -------------------------------\nclass NMTDataset(Dataset):\n    def __init__(self, src, tgt):\n        self.src = src\n        self.tgt = tgt\n    def __len__(self): return len(self.src)\n    def __getitem__(self, idx): return self.src[idx], self.tgt[idx]\n\nbatch_size = 32\ntrain_loader = DataLoader(NMTDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(NMTDataset(X_val, y_val), batch_size=batch_size)\ntest_loader  = DataLoader(NMTDataset(X_test, y_test), batch_size=batch_size)\n\n# -------------------------------\n# STEP 6: Define Seq2Seq Model\n# -------------------------------\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, enc_hid_dim, enc_layers, dropout, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, enc_hid_dim, num_layers=enc_layers,\n                            bidirectional=True, batch_first=True, dropout=dropout)\n    def forward(self, src):\n        embedded = self.embedding(src)\n        outputs, (hidden, cell) = self.lstm(embedded)\n        return outputs, hidden, cell\n\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, dec_hid_dim, dec_layers, dropout, pad_idx):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=pad_idx)\n        self.lstm = nn.LSTM(emb_dim, dec_hid_dim, num_layers=dec_layers,\n                            batch_first=True, dropout=dropout)\n        self.fc_out = nn.Linear(dec_hid_dim, output_dim)\n    def forward(self, input, hidden, cell):\n        embedded = self.embedding(input)\n        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n        prediction = self.fc_out(output)\n        return prediction, hidden, cell\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, pad_idx):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.pad_idx = pad_idx\n    def forward(self, src, tgt):\n        _, hidden, cell = self.encoder(src)\n        output, _, _ = self.decoder(tgt, hidden, cell)\n        return output\n\n# Instantiate\nEMBEDDING_DIM = 256\nENC_HID_DIM = 256\nDEC_HID_DIM = ENC_HID_DIM*2\nENC_LAYERS = 2\nDEC_LAYERS = 4\nENC_DROPOUT = 0.2\nDEC_DROPOUT = 0.2\n\nenc = Encoder(tokenizer_urdu.get_vocab_size(), EMBEDDING_DIM, ENC_HID_DIM,\n              ENC_LAYERS, ENC_DROPOUT, src_pad_id).to(device)\ndec = Decoder(tokenizer_roman.get_vocab_size(), EMBEDDING_DIM, DEC_HID_DIM,\n              DEC_LAYERS, DEC_DROPOUT, pad_id).to(device)\nmodel = Seq2Seq(enc, dec, pad_id).to(device)\n\n# -------------------------------\n# STEP 6B: Loss & Optimizer\n# -------------------------------\ncriterion = nn.CrossEntropyLoss(ignore_index=pad_id)\noptimizer = optim.Adam(model.parameters(), lr=5e-4)\n\nprint(\"Pipeline ready ✅ — run training loop next\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-21T15:26:54.726000Z","iopub.execute_input":"2025-09-21T15:26:54.726361Z","iopub.status.idle":"2025-09-21T15:26:56.343654Z","shell.execute_reply.started":"2025-09-21T15:26:54.726337Z","shell.execute_reply":"2025-09-21T15:26:56.342482Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nSplits: 657 328 329\n\n\n\nRoman pad: 1 sos: 0 eos: 2\nUrdu pad: 1\nPipeline ready ✅ — run training loop next\n","output_type":"stream"}],"execution_count":30}]}